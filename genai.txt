# GENAI.TXT - AI CONTEXT REFERENCE FOR DEVNAME RPG CLIENT
================================================================================
**CRITICAL NOTICE**: This document serves as the primary reference for generative AI to understand the complete project scope beyond its active context window. It enforces module boundaries and prevents regressions when modifying functions that affect multiple modules. Always consult this document before making changes that could ripple across the codebase.

## PROJECT OVERVIEW
Terminal-based RPG storytelling client using Large Language Models via MCP (Model Context Protocol). 
Architecture: Hub-and-spoke pattern with centralized orchestration through `orch.py`.
Status: Remodularization complete, debug logger interface standardized.

## CURRENT PROJECT STATE (Updated for Latest Commit Analysis)
- **Architecture**: Hub-and-spoke pattern fully implemented and operational
- **Debug Logger**: Interface standardized across all modules with method-based pattern
- **File Structure**: All 8 primary modules consolidated in root directory
- **Dependencies**: Python 3.8+, curses, httpx (optional for LLM communication)
- **Status**: Production-ready after successful remodularization

## COMPLETE MODULE REGISTRY AND INTERCONNECTS

### FILE STRUCTURE (All in root directory)
```
aurora-rp/
├── main.py              # Entry point, prompt management, debug logger
├── orch.py              # Central hub orchestrator - ONLY module calling mcp.py
├── mcp.py               # LLM communication - accessed ONLY by orch.py
├── ncui.py              # Pure UI controller (imports uilib.py)
├── uilib.py             # Consolidated UI components library
├── emm.py               # Enhanced memory manager
├── sme.py               # Story momentum engine  
├── sem.py               # Semantic analysis engine
├── critrules.prompt     # Core rules (REQUIRED)
├── lowrules.prompt      # Additional rules (optional)
├── companion.prompt     # Companion definitions (optional)
├── genai.txt            # This reference document
└── legacyref/           # Legacy code reference (read-only, do not modify)
```

### MODULE INTERCONNECTION MATRIX

#### main.py
**Purpose**: Application entry, prompt management, debug logging initialization
**Imports**: `orch.Orchestrator`
**Exports**: `DebugLogger`, `PromptManager`, `DevNameRPGClient`
**Data Sent**: 
- To orch.py: `config` dict, `loaded_prompts` dict, `debug_logger` object
**Data Received**: 
- From orch.py: Integer exit code
**Critical Functions**:
- `load_and_optimize_prompts()`: Condenses prompts to 5000 token budget
- `validate_prompt_files()`: Ensures critrules.prompt exists in root directory
- `DebugLogger.debug(message, category)`: Standardized logging interface
**Dependencies**: Python 3.8+, asyncio, pathlib
**File Paths**: All prompts loaded from same directory as Python files

#### orch.py (CENTRAL HUB)
**Purpose**: Central orchestration of all service modules
**Imports**: `ncui`, `emm`, `sme`, `sem`, `mcp`
**Exports**: `Orchestrator`, `OrchestrationState`, `OrchestrationPhase`
**Data Sent**:
- To ncui.py: Display messages, UI commands via callback
- To emm.py: Messages for storage, memory operations
- To sme.py: Story state updates, analysis triggers
- To sem.py: Analysis requests via orchestrator callback
- To mcp.py: LLM request payloads (EXCLUSIVE ACCESS)
**Data Received**:
- From ncui.py: User input strings, UI events, shutdown requests
- From emm.py: Message history, memory state, conversation context
- From sme.py: Momentum analysis results, antagonist state
- From sem.py: Semantic categorization results
- From mcp.py: LLM responses, error states
**Critical Functions**:
- `initialize_modules()`: Sets up all service modules with callbacks
- `_handle_ui_callback()`: Main coordination point
- `_process_user_input()`: Routes input through processing pipeline
- `_make_llm_request()`: ONLY function that calls mcp.py
- `_trigger_periodic_analysis()`: Manages 15-message analysis cycles
**Threading**: Background analysis thread for non-blocking operations
**Debug Logging**: Uses helper methods `_log_debug()`, `_log_error()`

#### mcp.py
**Purpose**: LLM communication via Model Context Protocol (HTTP-based)
**Imports**: None (leaf module)
**Exports**: `MCPClient`, `MCPRequestConfig`, `MCPResponse`
**Access Pattern**: EXCLUSIVELY called by orch.py - no other modules may import
**Data Sent**: LLM responses, error states, connection status
**Data Received**: LLM request payloads with prompts and context
**Critical Functions**:
- `make_request()`: Core LLM communication with 5-strategy JSON parsing
- `build_messages()`: Formats conversation for LLM context
- `_parse_response_content()`: Handles multiple response format strategies
**Dependencies**: httpx, asyncio, json
**Error Handling**: Graceful fallbacks, network timeout handling

#### ncui.py  
**Purpose**: Pure UI controller and event dispatcher
**Imports**: `uilib` (consolidated UI components)
**Exports**: `NCursesUIController`, `UIEvent`, `UIState`
**Data Sent**: User input strings, UI events, shutdown requests  
**Data Received**: Display messages, UI commands via orchestrator callback
**Critical Functions**:
- `run()`: Main UI event loop
- `_handle_user_input()`: Input processing and validation
- `_update_display()`: Coordinate UI refresh through uilib
- `_process_commands()`: Handle special commands (/help, /stats, etc.)
**Dependencies**: curses, uilib components
**Threading**: Main thread only, no direct threading operations

#### uilib.py
**Purpose**: Consolidated UI components library (replaces multiple nci_*.py files)
**Imports**: curses
**Exports**: `TerminalManager`, `MultiLineInput`, `ScrollManager`, `DisplayManager`, `ColorManager`
**Components**:
- `TerminalManager`: Dynamic coordinate system and layout geometry
- `MultiLineInput`: Multi-line input with cursor navigation and word wrapping
- `ScrollManager`: Scroll position management with bounds checking
- `DisplayManager`: Message formatting and display rendering
- `ColorManager`: Theme switching and color management
**Features**: 
- Dynamic coordinate system prevents layout bugs
- Responsive terminal geometry handling
- Intelligent submission detection (double-enter or sentence-ending punctuation)
- Three built-in color schemes (classic/dark/bright)
**Dependencies**: curses

#### emm.py
**Purpose**: Enhanced memory manager with semantic categorization
**Imports**: None (leaf module for storage)
**Exports**: `EnhancedMemoryManager`, `Message`, `MessageType`
**Data Sent**: Message history, memory state, conversation context
**Data Received**: Messages for storage, categorization updates
**Critical Functions**:
- `add_message()`: Thread-safe message storage with auto-save
- `get_conversation_for_mcp()`: Format messages for LLM requests
- `save_conversation()`: Atomic file operations with backup creation
- `get_condensation_candidates()`: Identify messages for LLM condensation
- `update_momentum_state()`: Persist story state from sme.py
**Threading**: Uses threading.Lock for all file operations
**Dependencies**: json, threading, pathlib
**Auto-save**: Background thread maintains state without blocking UI

#### sme.py  
**Purpose**: Story momentum engine with narrative pressure tracking
**Imports**: None (leaf module for analysis)
**Exports**: `StoryMomentumEngine`, `MomentumState`, `PressureType`
**Data Sent**: Momentum analysis results, antagonist state
**Data Received**: Story state updates, analysis triggers from orchestrator
**Critical Functions**:
- `analyze_momentum()`: Comprehensive LLM narrative analysis every 15 messages
- `update_pressure()`: Dynamic pressure tracking with floor ratcheting  
- `generate_antagonist()`: Quality-validated antagonist creation
- `get_momentum_state()`: Current story state for persistence
**Analysis Cycle**: Triggers every 15 messages via orchestrator
**Dependencies**: None (communicates via orchestrator callbacks)
**Threading**: Background LLM analysis to prevent UI blocking

#### sem.py
**Purpose**: Semantic analysis engine for message categorization  
**Imports**: None (leaf module for analysis)
**Exports**: `SemanticAnalysisEngine`, `ContentCategory`, `AnalysisResult`
**Data Sent**: Semantic categorization results
**Data Received**: Analysis requests via orchestrator callback
**Critical Functions**:
- `categorize_message()`: LLM-powered semantic categorization
- `analyze_content_importance()`: Determine condensation priority
- `batch_categorize()`: Efficient multi-message processing
**Categories**: character_focused, plot_advancing, world_building, meta_discussion, etc.
**Dependencies**: None (LLM requests routed through orchestrator)
**Threading**: Background processing via orchestrator coordination

## CRITICAL OPERATIONAL PATTERNS

### Debug Logger Interface (STANDARDIZED)
All modules use consistent method-based debug logging:
```python
def _log_debug(self, message: str, category: str = "general"):
    """Helper method for debug logging with null safety"""
    if self.debug_logger:
        self.debug_logger.debug(message, category)

def _log_error(self, message: str, category: str = "error"):
    """Helper method for error logging with null safety"""  
    if self.debug_logger:
        self.debug_logger.debug(f"ERROR: {message}", category)
```
- All modules handle None debug_logger gracefully
- Use category parameter for log organization
- No manual prefixes: Category parameter handles organization

### Service Module Initialization Pattern
All service modules must implement:
```python
def __init__(self, debug_logger=None):
    self.debug_logger = debug_logger
    self.orchestrator_callback = None

def set_orchestrator_callback(self, callback):
    self.orchestrator_callback = callback
```

### LLM Request Pattern (EXCLUSIVE ACCESS)
**ONLY orch.py may import and call mcp.py functions**
All other modules must use orchestrator callback:
```python
result = self.orchestrator_callback('llm_request', {
    'prompt': prompt_text,
    'context': context_data
})
```

### UI Callback Interface
ncui.py communicates with orch.py via callback:
```python
# UI to Orchestrator
result = self.callback_handler(action, data)

# Supported actions:
# "user_input", "get_messages", "clear_memory", 
# "get_stats", "analyze_now", "shutdown"
```

## CURRENT OPERATIONAL STATUS

### Successfully Implemented
- ✅ Hub-and-spoke architecture complete and operational
- ✅ Debug logger interface standardized across all modules
- ✅ All 8 modules consolidated in root directory
- ✅ Import path issues resolved
- ✅ Prompt file loading from root directory
- ✅ Threading safety with proper locks
- ✅ Memory auto-save functionality
- ✅ UI event handling and display refresh
- ✅ Exclusive LLM access pattern enforced
- ✅ Semantic categorization with background processing
- ✅ 15-message momentum analysis cycles

### Recently Completed Fixes
- ✅ Debug logger callable pattern → method pattern conversion
- ✅ Mixed debug logging interfaces standardized
- ✅ Orchestrator callback handler implementation
- ✅ UI component consolidation into uilib.py
- ✅ Prompt file path references corrected to root directory
- ✅ Module import dependencies resolved
- ✅ Threading safety in memory operations
- ✅ Background analysis coordination

### Testing Status
- **Startup Sequence**: Fully implemented and ready
- **Module Initialization**: All 8 modules initialize in dependency order
- **UI Display**: Consolidated uilib.py handles all interface operations  
- **Input Processing**: Complete pipeline through orchestrator
- **LLM Communication**: Exclusive access pattern operational
- **Memory Management**: Thread-safe with auto-save
- **Analysis Cycles**: Background processing prevents UI blocking

## REGRESSION PREVENTION RULES

### Before Modifying Any Function
1. **Check this document** for module interconnects and dependencies
2. **Identify all modules** that call the function
3. **Identify all modules** the function calls
4. **Consider data structure changes** and their ripple effects
5. **Verify threading implications** and race conditions
6. **Test with debug mode enabled** to verify logging works

### Hub-and-Spoke Enforcement
- **NEVER** allow direct module-to-module calls except through orch.py
- **NEVER** allow any module except orch.py to import mcp.py
- **NEVER** bypass the orchestrator callback pattern
- **ALWAYS** route cross-module communication through orchestrator

### Threading Safety Requirements
- emm.py uses threading.Lock for all file operations
- Background threads must not modify UI directly
- Analysis threads communicate results via orchestrator callbacks
- Auto-save runs independently with atomic file writes
- UI resizing must not lose message history or state

### Error Handling Patterns
- All modules must handle None debug_logger gracefully
- Network failures must not crash the application
- File I/O errors must be logged but not fatal
- Missing prompt files handled with warnings, not crashes
- Terminal resize must maintain application state

## TESTING CHECKLIST

### Startup Sequence Validation
- [ ] All 8 modules import successfully without errors
- [ ] Debug logger initializes and creates log file
- [ ] Prompt files load from root directory (critrules.prompt required)
- [ ] Orchestrator initializes all service modules in correct order
- [ ] UI displays without curses crashes

### Core Functionality Testing
- [ ] User input processes correctly through full pipeline
- [ ] LLM responses display properly in UI via orchestrator
- [ ] Messages save to memory.json automatically
- [ ] 15-message analysis triggers background processing
- [ ] Theme switching works with uilib.py color management
- [ ] Terminal resize maintains state and redisplays correctly

### Error Scenario Handling
- [ ] Missing prompt files handled gracefully with warnings
- [ ] Network timeout doesn't crash (falls back gracefully)
- [ ] Terminal resize during input doesn't lose cursor state
- [ ] Ctrl+C shuts down cleanly with proper cleanup
- [ ] Debug logger handles file write failures gracefully

### Command System Testing
- [ ] `/help` shows command documentation
- [ ] `/clear` clears display buffer
- [ ] `/stats` shows system statistics via orchestrator
- [ ] `/quit` and `/exit` trigger clean shutdown
- [ ] `/theme` command changes colors and refreshes display

### Advanced Feature Testing
- [ ] Semantic categorization operates in background
- [ ] Memory condensation when token limits exceeded
- [ ] Momentum analysis triggers every 15 messages
- [ ] Auto-save maintains conversation state
- [ ] Multi-line input with intelligent submission detection

## VERSION HISTORY

### Current Version (Latest Commit Analysis)
- **Architecture**: Complete hub-and-spoke implementation
- **Status**: Production-ready remodularized codebase
- **Debug Logger**: Standardized interface across all modules
- **UI Components**: Consolidated into uilib.py from multiple nci_*.py files
- **File Structure**: All 8 modules in root directory with flat organization
- **Key Features**: Centralized orchestration, standardized logging, responsive UI

### Previous Working Version (legacyref/)
- **Architecture**: Direct module interconnections
- **Status**: Fully functional but less maintainable  
- **Purpose**: Preserved for reference and emergency rollback
- **Usage**: Read-only reference, do not modify

### Major Changes from Legacy
- **Centralized Control**: All coordination through orch.py hub
- **Exclusive LLM Access**: Only orch.py calls mcp.py
- **Standardized Logging**: Consistent debug interface across modules
- **Flat File Structure**: All modules in root directory
- **Enhanced UI**: Consolidated uilib.py with better components
- **Thread Safety**: Improved locking and background processing
- **Error Handling**: Graceful degradation patterns

## USAGE INSTRUCTIONS

### Basic Operation
- Run `python main.py` to start with configuration auto-loading
- Use `python main.py --debug` for comprehensive logging
- Ensure critrules.prompt exists in root directory (required)
- companion.prompt and lowrules.prompt are optional
- Terminal minimum size: 80x24 characters

### Commands
- **Multi-line Input**: Type naturally, double-enter to submit
- **Navigation**: PgUp/PgDn for scrolling, Home/End for quick navigation
- **Commands**: `/help`, `/stats`, `/analyze`, `/theme <n>`, `/clearmemory`, `/quit`

### Debug Features
- Comprehensive logging of all module interactions
- Semantic categorization decision tracking
- Momentum analysis results monitoring
- Background thread operations visibility
- Token budget management logging
- Memory condensation process tracking

---
**END OF GENAI.TXT** - Last Updated: Analysis of latest commit state
**Remember**: This document is the authoritative source for understanding module interactions and preventing regressions. Always consult before making changes that could affect multiple modules. The hub-and-spoke architecture is complete and the project is production-ready.