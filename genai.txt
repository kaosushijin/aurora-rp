GENAI.TXT - AI ANALYSIS REFERENCE FOR DEVNAME RPG CLIENT
================================================================

PROJECT SCOPE:
Terminal-based RPG storytelling client leveraging Large Language Model capabilities through MCP (Model Control Protocol). Features innovative Story Momentum Engine, intelligent memory management, and complete rewrite of ncurses interface with immediate display architecture.

MODULE ARCHITECTURE:
main.py - Application coordination, prompt management, and lifecycle control
nci.py - Ncurses interface with immediate display pattern and integrated prompt system
mcp.py - HTTP client for MCP/Ollama server communication  
emm.py - Enhanced Memory Manager with LLM-powered semantic condensation
sme.py - Story Momentum Engine for narrative pressure management

CRITICAL INTERCONNECTS:
main.py → nci.py: Creates CursesInterface with loaded prompt configuration
nci.py → mcp.py: Sends integrated system messages via MCPClient methods
nci.py → emm.py: Stores/retrieves messages via EnhancedMemoryManager
nci.py → sme.py: Updates narrative pressure via StoryMomentumEngine.process_user_input()
mcp.py ← sme.py: Receives story context via get_story_context()
mcp.py ← emm.py: Receives conversation history via get_conversation_for_mcp()

DATA FLOW:
1. Prompts loaded and optimized in main.py during startup
2. User input captured in nci.py with immediate display multi-line input system
3. Message stored in emm.py with automatic semantic analysis
4. Narrative pressure updated in sme.py based on input patterns
5. System messages built from loaded prompts + story context + conversation history
6. MCP request sent with complete message chain, response received
7. Response displayed in nci.py interface with immediate refresh pattern

CONFIGURATION SYSTEM:
- Hardcoded configuration values in ApplicationConfig class
- memory.json: Persistent conversation memory (auto-created)
- Prompt files: critrules.prompt (required), companion.prompt, lowrules.prompt
- debug.log: Debug logging when --debug flag enabled

APPLICATION ENTRY POINT (main.py):
================================================================

ENHANCED PROMPT MANAGEMENT SYSTEM:
- PromptManager class with intelligent loading and condensation
- Token budget allocation (5,000 tokens for all prompts combined)
- Automatic prompt condensation using LLM when budget exceeded
- Critical validation ensuring critrules.prompt exists
- Graceful handling of missing optional prompt files

MAIN CLASS STRUCTURE:
- DevNameRPGClient: Primary application coordinator with prompt integration
- DebugLogger: Centralized logging system shared across modules
- ApplicationConfig: Hardcoded configuration management (no file creation)
- PromptManager: Handles prompt loading, optimization, and condensation

INITIALIZATION SEQUENCE:
1. Argument parsing and environment setup
2. Module verification and dependency checking
3. Hardcoded configuration loading
4. Debug logger initialization if enabled
5. Async prompt loading and optimization phase
6. CursesInterface creation with prompt injection
7. Signal handlers for graceful shutdown

PROMPT OPTIMIZATION ALGORITHM:
1. Load all available prompt files with graceful missing file handling
2. Calculate combined token usage with conservative estimation
3. Apply LLM-powered condensation if exceeding 5k token budget
4. Individual prompt condensation for files >1/3 of total budget
5. Verification of condensation effectiveness
6. Pass optimized prompts to interface configuration

CONFIGURATION DEFAULTS:
- MCP server: http://127.0.0.1:3456/chat
- MCP model: qwen2.5:14b-instruct-q4_k_m
- MCP timeout: 300 seconds
- Memory max tokens: 16,000
- Interface color theme: classic
- Story pressure decay: 0.05
- Antagonist threshold: 0.6

DEPENDENCY MANAGEMENT:
- Required: curses module (with platform-specific guidance)
- Required: httpx for MCP communication and prompt condensation
- Module verification system for all components
- Graceful degradation messaging for missing dependencies

NCURSES INTERFACE MODULE (nci.py) - COMPLETE REWRITE:
================================================================

IMMEDIATE DISPLAY ARCHITECTURE:
- All message display methods use "_immediate" suffix for real-time updates
- Every display operation triggers immediate window refresh
- Explicit cursor management after every interface operation
- No backwards compatibility wrappers - clean API surface
- Synchronous display updates with no batched operations

CORE INTERFACE CLASSES:
- CursesInterface: Main controller with immediate display integration
- MultiLineInput: Advanced multi-line input with cursor navigation and word wrapping
- ScrollManager: Enhanced scrolling with page navigation and scroll indicators
- TerminalManager: Dynamic terminal management with real-time resize handling
- DisplayMessage: Message formatting with new prefix system (GM instead of AI)
- ColorManager: Theme-based color management (classic/dark/bright)
- InputValidator: Token estimation and multi-line input validation

MULTI-LINE INPUT SYSTEM:
- Full cursor navigation with arrow keys (left/right/up/down)
- Word wrapping at terminal boundaries with intelligent break points
- Intelligent submission detection (punctuation endings or commands)
- Line merging on backspace across line boundaries
- Character limit (4000) and line limit (20) for reasonable usage
- Real-time display formatting within input window constraints

ENHANCED SCROLLING SYSTEM:
- Page-based navigation with PgUp/PgDn keys
- Home/End keys for instant top/bottom navigation
- Scroll indicators in status bar showing position and scrollback state
- Auto-return to bottom on new message submission
- SCROLLBACK indicator when viewing history (not at bottom)
- Single-line scroll with arrow keys when not in input mode

DYNAMIC TERMINAL MANAGEMENT:
- Real-time resize detection every 0.5 seconds
- Minimum size validation (80x24) with helpful error messages
- Complete window recreation and content rewrapping on resize
- Graceful degradation for terminals that are too small
- Automatic dimension recalculation and component reinitialization

MESSAGE DISPLAY IMPROVEMENTS:
- Changed "AI:" prefix to "GM:" for Game Master branding
- Changed "System:" prefix to clean space " :" for visual hierarchy
- True blank lines between GM responses for better readability
- Immediate display refresh on every message addition
- Proper color coding with theme support

WINDOW MANAGEMENT:
- Output window: Conversation display with enhanced scroll support
- Input window: Multi-line user input with real-time validation
- Status window: Enhanced statistics including scroll position and prompt count
- Automatic dimension calculation with proportional screen usage
- Border drawing with immediate refresh

NO MCP CONNECTION TESTING:
- Eliminated startup connection testing entirely
- Errors only displayed during actual communication attempts
- Specific error types: ConnectionError, TimeoutError, general exceptions
- Graceful fallback patterns for MCP communication failures
- Clean startup experience without unnecessary error messages

PROMPT INTEGRATION WORKFLOW:
- _build_system_messages(): Constructs integrated prompt chain
- Primary prompt (critrules) enhanced with story context injection
- Companion and narrative prompts added as separate system messages
- Custom MCP request building with complete message structure
- Fallback to standard send_message if custom approach fails

INPUT PROCESSING ARCHITECTURE:
- Character-by-character input building with immediate visual feedback
- Enter key intelligent submission vs. new line creation
- Enhanced navigation: arrow keys, page navigation, home/end positioning
- Real-time input validation with token estimation
- Command processing: /help, /quit, /clear, /stats, /theme (removed /prompts)

INTERFACE METHOD NAMING:
- add_user_message_immediate(): User message display with immediate refresh
- add_assistant_message_immediate(): GM message with blank line separation
- add_system_message_immediate(): System message with immediate refresh
- add_error_message_immediate(): Error message with debug logging
- set_processing_state_immediate(): Processing state with visual feedback
- _add_message_immediate(): Core message addition with display update
- _add_blank_line_immediate(): True blank line insertion with refresh

ENHANCED DEBUGGING UTILITIES:
- get_display_state(): Comprehensive interface state inspection
- get_input_state(): Multi-line input state analysis
- get_scroll_position(): Scroll manager state information
- simulate_user_input(): Automated input testing
- simulate_resize(): Terminal resize testing
- test_all_navigation_keys(): Navigation functionality testing
- force_refresh_display(): Emergency display recovery

MCP COMMUNICATION MODULE (mcp.py):
================================================================

STREAMLINED ARCHITECTURE:
- MCPClient class with essential HTTP communication
- Single retry mechanism (MCP_MAX_RETRIES = 2)
- Clean context integration from EMM and SME modules
- Eliminated performance monitoring for simplicity

CORE FUNCTIONALITY:
- MCPClient.send_message(): Primary interface with story context integration
- MCPClient._execute_request(): Direct request execution for custom message chains
- MCPClient.test_connection(): Async connection verification
- MCPClient.get_server_info(): Basic diagnostics
- MCPClient.update_system_prompt(): Dynamic prompt modification

ERROR HANDLING:
- Single exception type for all MCP failures
- Debug-only verbose logging
- Graceful fallback when httpx unavailable
- Brief retry delays (1 second) without complex backoff

CONTEXT INTEGRATION DESIGN:
- Story context from SME injected as system message
- Conversation history from EMM limited to last 10 messages
- System prompt + story context + history + user input = complete chain
- Minimal response validation for essential structure checking

ASYNC EXECUTION PATTERN:
- Creates new event loop for each request (avoiding conflicts)
- Simple async/await pattern with httpx.AsyncClient
- Timeout management through httpx configuration
- Clean loop closure after execution

DEFAULT SYSTEM PROMPT:
High-fantasy RPG Game Master instructions for immersive storytelling, rich descriptions, engaging NPCs, and dynamic narrative responses.

ENHANCED MEMORY MANAGER MODULE (emm.py):
================================================================

SEMANTIC ANALYSIS SYSTEM:
- LLM-powered message categorization with 6 semantic categories
- Context-aware analysis using 11-message window (5 before + target + 5 after)
- 3-tier retry system: Full Analysis → Simple Analysis → Binary Decision
- Pure LLM-driven semantic decisions with programmatic fallbacks

SEMANTIC CATEGORIES & PRESERVATION RATIOS:
- story_critical: 0.9 (90% preservation) - Major plot developments, character deaths, world-changing events
- character_focused: 0.8 (80% preservation) - Relationship changes, character development, personality reveals
- relationship_dynamics: 0.8 (80% preservation) - Evolving relationships between characters
- emotional_significance: 0.75 (75% preservation) - Dramatic moments, trust/betrayal, conflict resolution
- world_building: 0.7 (70% preservation) - New locations, lore, cultural info, political changes
- standard: 0.4 (40% preservation) - General interactions, travel, routine activities

PROGRESSIVE CONDENSATION SYSTEM:
- Multi-pass condensation with increasing aggressiveness (up to 3 passes)
- Aggressiveness reduces preservation ratios by 0.1 per pass
- Minimum preservation ratio of 0.2 to prevent critical information loss
- Recent messages (last 5) always protected from condensation

FRAGMENTATION LOGIC:
- LLM identifies multi-category messages and fragments appropriately
- Each fragment assigned individual categories and importance scores
- Multi-category fragments use highest applicable preservation ratio
- Semantic fragmentation for complex messages with multiple elements

MEMORY MANAGEMENT ALGORITHM:
1. Add message → check token threshold → trigger condensation if needed
2. Analyze condensable messages (excluding recent 5) for semantic importance
3. Apply category-weighted preservation ratios adjusted for aggressiveness
4. Group messages for condensation and create LLM-generated summary
5. Replace condensed messages with summary, preserve important messages
6. Repeat up to 3 passes if memory still exceeds threshold

THREAD SAFETY & ASYNC OPERATIONS:
- Thread-safe message storage with locking mechanisms
- Async LLM calls for semantic analysis without blocking interface
- Non-blocking condensation operations in separate event loop
- Safe concurrent access to conversation history

EMM INTERFACE FOR OTHER MODULES:
- get_conversation_for_mcp(): Returns formatted conversation for MCP requests
- add_message(): Thread-safe message storage with automatic condensation
- get_messages(): Retrieves conversation history with optional limits
- get_memory_stats(): Returns current memory utilization statistics
- save_conversation(): Persistent storage with metadata
- load_conversation(): Restore from saved files
- analyze_conversation_patterns(): Debug and analysis functionality

STORY MOMENTUM ENGINE MODULE (sme.py):
================================================================

NARRATIVE PRESSURE SYSTEM:
- Dynamic pressure tracking on 0.0-1.0 scale with pattern-based calculation
- Real-time story arc progression: Setup → Rising Action → Climax → Resolution
- Context-adaptive antagonist generation based on user input patterns
- Rate limiting (2-second cooldown) to prevent spam-induced pressure spikes

PRESSURE CALCULATION ALGORITHM:
- Pattern-based analysis using 6 momentum categories
- Weighted keyword matching with dynamic pressure deltas per category
- Length/complexity factors and punctuation intensity analysis
- Natural pressure decay over time (0.05 per minute) to prevent inflation
- Maximum single increase cap of 0.3 to prevent extreme spikes

MOMENTUM PATTERN CATEGORIES:
- conflict: Keywords trigger +0.15 pressure (fight, attack, defend, battle, combat, strike)
- tension: Keywords trigger +0.12 pressure (danger, threat, fear, worry, concern, risk)
- mystery: Keywords trigger +0.08 pressure (strange, unusual, mysterious, hidden, secret, whisper)
- exploration: Keywords trigger +0.05 pressure (examine, search, look, investigate, explore, discover)
- social: Keywords trigger +0.03 pressure (talk, speak, negotiate, persuade, convince, ask)
- resolution: Keywords trigger -0.10 pressure (resolve, solution, answer, complete, finish, end)

STORY ARC THRESHOLDS:
- Setup Arc: 0.0-0.3 pressure (calm exploration, building tension)
- Rising Action: 0.3-0.7 pressure (escalating conflict)
- Climax: 0.7-0.9 pressure (peak intensity)
- Resolution: 0.9-1.0 pressure (concluding action)

ANTAGONIST MANAGEMENT:
- Context-adaptive antagonist generation at 0.6 pressure threshold
- Dynamic antagonist types based on recent user input analysis:
  * magical_opposition: Corrupted Mage (magic/spell keywords detected)
  * environmental_threat: Ancient Guardian (exploration/dungeon keywords)
  * social_conflict: Corrupt Official (town/people keywords)
  * adaptive_threat: Shadow Entity (default context-adaptive)
- Threat level scaling with current pressure level
- Automatic deactivation during Resolution arc

CONTEXT GENERATION FOR MCP:
- Comprehensive story context including pressure level, arc, narrative state
- Antagonist information when present (name, motivation, threat level, active status)
- Pressure trend analysis (rising/falling/stable) based on recent history
- Narrative state descriptions: calm_exploration, building_tension, escalating_conflict, peak_intensity, concluding_action
- Tension introduction flags and climax approach indicators

SME INTERFACE FOR OTHER MODULES:
- process_user_input(): Updates pressure and returns processing results
- get_story_context(): Returns story context for MCP integration
- reset_story_state(): Clears state for new sessions
- get_pressure_stats(): Returns pressure analytics and statistics
- save_state(): Persistent state management
- load_state(): State restoration
- get_debug_info(): Comprehensive debug information

PROMPT SYSTEM INTEGRATION:
================================================================

PROMPT FILE ARCHITECTURE:
- critrules.prompt: Core GM rules and character control boundaries (REQUIRED)
- companion.prompt: Active companion character definition (OPTIONAL)
- lowrules.prompt: World generation and environmental storytelling rules (OPTIONAL)

COMPANION PROMPT TEMPLATES:
- tsundere_companion.prompt: Seraphina knight companion template
- dandere_companion.prompt: Elena healer companion template
- kuudere_companion.prompt: Lysander mage companion template
- himedere_companion.prompt: Victoria noble companion template

INTELLIGENT PROMPT LOADING:
- Graceful handling of missing files with user warnings
- Automatic token estimation and budget management
- LLM-powered condensation when exceeding 5k token allocation
- Preservation of essential functionality during condensation
- Status display showing active prompt components in interface

PROMPT INTEGRATION WORKFLOW:
1. Load available prompt files during startup
2. Apply condensation if budget exceeded
3. Pass optimized prompts to interface configuration
4. Build dynamic system messages with story context injection
5. Combine prompts + context + history for complete message chain
6. Real-time status display showing active prompt count

TOKEN BUDGET ALLOCATION:
- Total Context Window: 32,000 tokens
- System Prompts: 5,000 tokens (auto-optimized)
- Memory Storage: 16,000 tokens (semantic categorization)
- Input Buffer: Remaining capacity with validation

MODULAR PRESERVATION RULES:
================================================================

1. Breaking interconnects between modules will cause system failure
2. Enhanced Memory Manager maintains specific interface methods for other modules
3. Story Momentum Engine maintains specific interface methods for other modules
4. MCP Communication Module maintains specific interface methods for other modules
5. LLM semantic analysis requires functional MCP configuration
6. Prompt system requires critrules.prompt for core functionality
7. File persistence maintains metadata for debugging and analysis
8. Interface immediate display methods must maintain synchronous operation
9. Multi-line input system requires proper cursor management
10. Terminal resize handling must preserve scroll position and input state

ERROR HANDLING HIERARCHY:
- main.py: Application-level errors, prompt loading failures, graceful shutdown
- nci.py: Interface errors, display failures, terminal management, immediate refresh failures
- mcp.py: Network errors and communication failures (simplified single exception type)
- emm.py: Memory management errors, LLM analysis failures, condensation errors
- sme.py: Narrative analysis and context generation errors

DEBUGGING INFRASTRUCTURE:
- Centralized DebugLogger class in main.py shared across all modules
- Enhanced memory debugging with semantic analysis tracking
- LLM interaction logging for prompt optimization
- Token usage monitoring and condensation effectiveness metrics
- Story pressure tracking and antagonist lifecycle monitoring
- Prompt loading and condensation process logging
- Simplified MCP communication logging (debug-only verbosity)
- Interface state inspection and testing utilities
- Multi-line input debugging and simulation capabilities
- Terminal resize testing and recovery mechanisms

PERFORMANCE CONSIDERATIONS:
- LLM semantic analysis adds latency but provides superior memory management
- Async operations prevent interface blocking during condensation
- Context window analysis balances accuracy with computational cost
- Progressive aggressiveness ensures memory constraints are met
- Story pressure calculation optimized for real-time performance
- Rate limiting prevents computational overhead from input spam
- Prompt condensation reduces token usage while preserving functionality
- Simplified MCP retry logic reduces communication overhead
- Immediate display pattern adds refresh overhead but improves user experience
- Multi-line input processing optimized for real-time character insertion
- Terminal resize handling optimized to minimize disruption

DEPENDENCY REQUIREMENTS:
- Python 3.8+ with curses support
- httpx library for HTTP communication (REQUIRED for full functionality)
- asyncio for non-blocking LLM calls in memory management
- JSON for configuration and history storage
- Threading for thread-safe memory operations
- textwrap for multi-line input word wrapping

AI MODIFICATION GUIDELINES:
================================================================

1. PRESERVE all programmatic interconnects when modifying any module
2. UPDATE this genai.txt file when making architectural changes
3. MAINTAIN the single responsibility principle for each module
4. DO NOT merge module responsibilities or break the modular boundaries
5. VERIFY that changes do not break the data flow patterns
6. TEST interconnects after any modifications to ensure system integrity
7. LLM prompt modifications require extensive testing for reliability
8. Semantic category changes must update preservation ratios accordingly
9. Story pressure thresholds and antagonist generation logic must remain context-adaptive
10. Pattern-based pressure calculation should maintain balance between categories
11. Prompt system modifications must maintain critrules.prompt as required dependency
12. Token budget changes require corresponding updates to allocation constants
13. Condensation logic changes must preserve essential prompt functionality
14. System message building must maintain prompt integration order and structure
15. Interface display methods must maintain immediate refresh pattern
16. Multi-line input modifications must preserve cursor navigation functionality
17. Terminal management changes must maintain dynamic resize capability
18. Scrolling system modifications must preserve page navigation and indicators
19. Color theme changes must maintain accessibility and visual hierarchy
20. Error handling modifications must preserve specific error type reporting

ARCHITECTURAL INNOVATIONS:
================================================================

STORY MOMENTUM ENGINE:
- Mathematical pressure modeling prevents common AI storytelling pitfalls
- Context-adaptive antagonist generation based on player behavior patterns
- Natural pressure decay prevents artificial tension inflation
- Rate limiting prevents exploitation through rapid inputs

INTELLIGENT MEMORY MANAGEMENT:
- LLM-powered semantic categorization with multi-tier retry system
- Progressive condensation with category-weighted preservation
- Thread-safe operations with async LLM calls
- Fragmentation logic for complex multi-category messages

INTEGRATED PROMPT SYSTEM:
- Dynamic prompt loading with intelligent condensation
- Token budget management with automatic optimization
- Story context injection into core GM rules
- Multi-prompt integration with hierarchical message building

IMMEDIATE DISPLAY ARCHITECTURE:
- Real-time interface updates with explicit cursor management
- Multi-line input system with intelligent submission detection
- Enhanced scrolling with page navigation and visual indicators
- Dynamic terminal management with seamless resize handling

TECHNICAL EXCELLENCE:
- Graceful degradation with missing components
- Comprehensive error handling with debug transparency
- Modular architecture with clear separation of concerns
- Real-time status monitoring and user feedback
- Clean API surface without backwards compatibility baggage
- Comprehensive testing and debugging utilities for development support

INTERFACE REWRITE ACHIEVEMENTS:
================================================================

1. MCP DETECTION REMOVAL: Eliminated startup connection testing for cleaner initialization
2. MESSAGE PREFIX IMPROVEMENTS: AI→GM branding, clean system message formatting
3. MULTI-LINE INPUT SYSTEM: Full cursor navigation, word wrapping, intelligent submission
4. ENHANCED SCROLLING: Page navigation, position indicators, auto-return behavior
5. DYNAMIC TERMINAL MANAGEMENT: Real-time resize, minimum size validation, content rewrapping
6. IMMEDIATE DISPLAY PATTERN: Synchronous updates, explicit cursor management, no batching
7. COMMAND SIMPLIFICATION: Removed /prompts, enhanced help and stats
8. ROBUST ERROR HANDLING: Specific error types, contextual messages, graceful fallbacks
9. TESTING UTILITIES: State inspection, input simulation, navigation testing
10. CLEAN API SURFACE: No backwards compatibility wrappers, consistent method naming