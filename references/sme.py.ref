# Chunk 1/3 - sme.py - Story Momentum Engine with Semantic Time Detection
#!/usr/bin/env python3

import json
import re
import asyncio
from datetime import datetime
from enum import Enum
from typing import Dict, List, Optional, Any, Tuple
import httpx

class StoryArc(Enum):
    """Narrative progression states"""
    SETUP = "setup"
    RISING = "rising_action" 
    CLIMAX = "climax"
    RESOLUTION = "resolution"

class Antagonist:
    """Dynamic story opposition element"""
    
    def __init__(self, name: str, motivation: str, threat_level: float, context: str):
        self.name = name
        self.motivation = motivation
        self.threat_level = threat_level  # 0.0-1.0
        self.context = context
        self.introduction_sequence = 0  # Narrative sequence instead of real time
        self.active = True
        self.commitment_level = "testing"  # testing → engaged → desperate → cornered
        self.resources_available = []
        self.resources_lost = []
        self.personality_traits = []
        self.background = ""
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "name": self.name,
            "motivation": self.motivation,
            "threat_level": self.threat_level,
            "context": self.context,
            "introduction_sequence": self.introduction_sequence,
            "active": self.active,
            "commitment_level": self.commitment_level,
            "resources_available": self.resources_available,
            "resources_lost": self.resources_lost,
            "personality_traits": self.personality_traits,
            "background": self.background
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'Antagonist':
        antagonist = cls(
            data["name"],
            data["motivation"], 
            data["threat_level"],
            data["context"]
        )
        antagonist.introduction_sequence = data.get("introduction_sequence", 0)
        antagonist.active = data.get("active", True)
        antagonist.commitment_level = data.get("commitment_level", "testing")
        antagonist.resources_available = data.get("resources_available", [])
        antagonist.resources_lost = data.get("resources_lost", [])
        antagonist.personality_traits = data.get("personality_traits", [])
        antagonist.background = data.get("background", "")
        return antagonist

class NarrativeTimeTracker:
    """Tracks narrative time progression separate from real time"""
    
    def __init__(self):
        self.total_narrative_seconds = 0.0
        self.exchange_count = 0
        self.sequence_history: List[Tuple[int, float, float]] = []  # (sequence, duration, cumulative_time)
        
        # Semantic time detection patterns
        self.quick_patterns = {
            "brief_dialogue": [r"\b(yes|no|okay|sure|maybe|perhaps)\b", r"^[^.!?]{1,20}[.!?]?$"],
            "reactions": [r"\b(gasp|nod|shake|shrug|smile|frown|laugh)\b", r"\bdraw|dodge|duck|jump\b"],
            "simple_looks": [r"^I (look|glance|peek)", r"\blook around\b"]
        }
        
        self.complex_patterns = {
            "detailed_actions": [r"\bcarefully|thoroughly|methodically|slowly\b", r"\bexamine.*detail", r"\bsearch.*room\b"],
            "spellcasting": [r"\bcast|spell|magic|ritual|incantation\b", r"\bmutter.*words\b"],
            "negotiation": [r"\bnegotiate|persuade|convince|bargain\b", r"\bexplain.*detail\b"],
            "crafting": [r"\bcraft|repair|fix|mend|build\b", r"\bwork.*tools\b"]
        }
        
        self.extended_patterns = {
            "travel": [r"\btravel|walk|journey|head.*to\b", r"\bmake.*way\b"],
            "rest": [r"\brest|sleep|camp|break\b", r"\btake.*time\b"],
            "research": [r"\bstudy|research|read.*book|examine.*text\b"],
            "planning": [r"\bplan|discuss|strategy|consider.*options\b"]
        }
        
        self.transition_patterns = {
            "time_skip": [r"\bafter.*time|later|eventually|meanwhile\b", r"\bhours?|minutes?|days?\b"],
            "scene_change": [r"\bwe (arrive|reach|enter)\b", r"\bthe next (day|morning|evening)\b"]
        }
    
    def calculate_semantic_duration(self, content: str) -> float:
        """Calculate narrative duration based on semantic content analysis"""
        if not content or not content.strip():
            return 10.0  # Default fallback
        
        content_lower = content.lower()
        
        # Check for explicit time references first
        explicit_time = self._extract_explicit_time(content_lower)
        if explicit_time:
            return explicit_time
        
        # Check transition patterns (highest priority)
        if self._matches_patterns(content_lower, self.transition_patterns):
            return self._calculate_transition_duration(content_lower)
        
        # Check extended action patterns
        if self._matches_patterns(content_lower, self.extended_patterns):
            return self._calculate_extended_duration(content_lower)
        
        # Check complex action patterns
        if self._matches_patterns(content_lower, self.complex_patterns):
            return self._calculate_complex_duration(content_lower)
        
        # Check quick action patterns
        if self._matches_patterns(content_lower, self.quick_patterns):
            return self._calculate_quick_duration(content_lower)
        
        # Default to 10 seconds for standard actions
        return 10.0
    
    def _extract_explicit_time(self, content: str) -> Optional[float]:
        """Extract explicit time references from content"""
        # Patterns for explicit time mentions
        time_patterns = [
            (r"(\d+)\s*hours?", 3600),
            (r"(\d+)\s*minutes?", 60),
            (r"(\d+)\s*seconds?", 1),
            (r"half\s*hour", 1800),
            (r"quarter\s*hour", 900),
            (r"a\s*few\s*minutes?", 180),
            (r"several\s*minutes?", 300),
            (r"moment|instant|quickly", 5),
            (r"while|bit", 30)
        ]
        
        for pattern, multiplier in time_patterns:
            match = re.search(pattern, content)
            if match:
                if match.groups():
                    return float(match.group(1)) * multiplier
                else:
                    return float(multiplier)
        
        return None
    
    def _matches_patterns(self, content: str, pattern_dict: Dict[str, List[str]]) -> bool:
        """Check if content matches any patterns in the given category"""
        for category_patterns in pattern_dict.values():
            for pattern in category_patterns:
                if re.search(pattern, content):
                    return True
        return False
    
    def _calculate_quick_duration(self, content: str) -> float:
        """Calculate duration for quick actions (3-8 seconds)"""
        word_count = len(content.split())
        if word_count <= 3:
            return 3.0
        elif word_count <= 10:
            return 5.0
        else:
            return 8.0
    
    def _calculate_complex_duration(self, content: str) -> float:
        """Calculate duration for complex actions (15-45 seconds)"""
        word_count = len(content.split())
        if "carefully" in content or "thoroughly" in content:
            return min(45.0, 20.0 + (word_count * 0.5))
        elif "spell" in content or "magic" in content:
            return min(30.0, 15.0 + (word_count * 0.3))
        else:
            return min(35.0, 15.0 + (word_count * 0.4))
    
    def _calculate_extended_duration(self, content: str) -> float:
        """Calculate duration for extended actions (1-5 minutes)"""
        if "travel" in content or "journey" in content:
            return 300.0  # 5 minutes default for travel
        elif "rest" in content or "sleep" in content:
            return 600.0  # 10 minutes for rest
        elif "study" in content or "research" in content:
            return 180.0  # 3 minutes for research
        else:
            return 120.0  # 2 minutes default
    
    def _calculate_transition_duration(self, content: str) -> float:
        """Calculate duration for narrative transitions (5+ minutes)"""
        if "hours" in content:
            return 3600.0  # 1 hour
        elif "day" in content:
            return 7200.0  # 2 hours (representative portion of day)
        elif "evening" in content or "morning" in content:
            return 1800.0  # 30 minutes
        else:
            return 600.0  # 10 minutes default transition
    
    def add_exchange(self, content: str) -> float:
        """Add new exchange and return narrative duration"""
        duration = self.calculate_semantic_duration(content)
        self.exchange_count += 1
        self.total_narrative_seconds += duration
        
        # Record in history
        self.sequence_history.append((
            self.exchange_count,
            duration, 
            self.total_narrative_seconds
        ))
        
        # Keep history manageable
        if len(self.sequence_history) > 200:
            self.sequence_history = self.sequence_history[-100:]
        
        return duration
    
    def get_narrative_time_since_sequence(self, sequence_number: int) -> float:
        """Get narrative time elapsed since a specific sequence number"""
        if not self.sequence_history:
            return 0.0
        
        # Find the sequence in history
        for seq, duration, cumulative in self.sequence_history:
            if seq == sequence_number:
                return self.total_narrative_seconds - cumulative
        
        # If not found, estimate based on current position
        sequences_passed = max(0, self.exchange_count - sequence_number)
        return sequences_passed * 10.0  # Conservative estimate
    
    def get_stats(self) -> Dict[str, Any]:
        """Get narrative time tracking statistics"""
        avg_duration = (self.total_narrative_seconds / self.exchange_count 
                       if self.exchange_count > 0 else 0.0)
        
        return {
            "total_narrative_seconds": self.total_narrative_seconds,
            "total_narrative_minutes": self.total_narrative_seconds / 60.0,
            "exchange_count": self.exchange_count,
            "average_duration_per_exchange": avg_duration,
            "narrative_time_formatted": self._format_narrative_time(self.total_narrative_seconds)
        }
    
    def _format_narrative_time(self, seconds: float) -> str:
        """Format narrative time for display"""
        if seconds < 60:
            return f"{seconds:.0f}s"
        elif seconds < 3600:
            minutes = seconds / 60
            return f"{minutes:.1f}m"
        else:
            hours = seconds / 3600
            return f"{hours:.1f}h"

# Chunk 2/3 - sme.py - StoryMomentumEngine Class with Narrative Time Integration

class StoryMomentumEngine:
    """
    Dynamic narrative pressure and antagonist management system with semantic time detection.
    Analyzes conversation for story pacing using narrative time instead of real time.
    """
    
    def __init__(self, debug_logger=None):
        self.debug_logger = debug_logger
        self.pressure_level = 0.0  # 0.0-1.0 scale
        self.story_arc = StoryArc.SETUP
        self.current_antagonist: Optional[Antagonist] = None
        self.narrative_tracker = NarrativeTimeTracker()
        
        # Analysis cycle tracking (every 15 messages)
        self.last_analysis_count = 0
        self.escalation_count = 0
        self.base_pressure_floor = 0.0
        
        # Narrative time pressure tracking
        self.pressure_history: List[Tuple[int, float, float]] = []  # (sequence, pressure, narrative_time)
        self.last_pressure_decay_sequence = 0
        
        # Pressure calculation parameters
        self.pressure_decay_per_minute = 0.05  # Decay rate per narrative minute
        self.pressure_threshold_antagonist = 0.6
        self.pressure_threshold_climax = 0.8
        
        # MCP configuration for LLM calls
        self.mcp_config = {
            "server_url": "http://127.0.0.1:3456/chat",
            "model": "qwen2.5:14b-instruct-q4_k_m",
            "timeout": 300
        }
        
        # Story momentum patterns (for immediate feedback)
        self.momentum_patterns = {
            "conflict": ["fight", "attack", "defend", "battle", "combat", "strike"],
            "exploration": ["examine", "search", "look", "investigate", "explore", "discover"],
            "social": ["talk", "speak", "negotiate", "persuade", "convince", "ask"],
            "mystery": ["strange", "unusual", "mysterious", "hidden", "secret", "whisper"],
            "tension": ["danger", "threat", "fear", "worry", "concern", "risk"],
            "resolution": ["resolve", "solution", "answer", "complete", "finish", "end"]
        }
    
    def _log_debug(self, message: str):
        """Internal debug logging"""
        if self.debug_logger:
            self.debug_logger.debug(f"SME: {message}", "SME")
    
    async def _call_llm(self, messages: List[Dict[str, str]]) -> Optional[str]:
        """Make LLM request for momentum analysis using working MCP format"""
        try:
            async with httpx.AsyncClient(timeout=self.mcp_config.get("timeout", 30)) as client:
                payload = {
                    "model": self.mcp_config["model"],
                    "messages": messages,
                    "stream": False
                }

                response = await client.post(self.mcp_config["server_url"], json=payload)
                response.raise_for_status()

                if response.status_code == 200:
                    result = response.json()
                    return result.get("message", {}).get("content", "")

        except Exception as e:
            if self.debug_logger:
                self.debug_logger.error(f"SME LLM call failed: {e}")
            return None
    
    def _calculate_pressure_change(self, input_text: str) -> float:
        """Calculate immediate pressure change based on user input patterns"""
        if not input_text.strip():
            return 0.0
        
        text_lower = input_text.lower()
        pressure_delta = 0.0
        
        # Pattern-based pressure calculation for immediate feedback
        for pattern_type, keywords in self.momentum_patterns.items():
            matches = sum(1 for keyword in keywords if keyword in text_lower)
            
            if pattern_type == "conflict":
                pressure_delta += matches * 0.15
            elif pattern_type == "tension":
                pressure_delta += matches * 0.12
            elif pattern_type == "mystery":
                pressure_delta += matches * 0.08
            elif pattern_type == "exploration":
                pressure_delta += matches * 0.05
            elif pattern_type == "social":
                pressure_delta += matches * 0.03
            elif pattern_type == "resolution":
                pressure_delta -= matches * 0.10
        
        # Length and complexity factors
        word_count = len(text_lower.split())
        if word_count > 20:
            pressure_delta += 0.05
        
        # Question pattern detection
        if "?" in input_text:
            pressure_delta += 0.03
        
        # Exclamation intensity
        exclamation_count = input_text.count("!")
        pressure_delta += min(exclamation_count * 0.02, 0.08)
        
        return min(pressure_delta, 0.3)  # Cap maximum single increase

    def _apply_narrative_pressure_decay(self):
        """Apply pressure decay based on narrative time progression instead of real time"""
        current_narrative_time = self.narrative_tracker.total_narrative_seconds
        
        # Get narrative time since last decay calculation
        if self.last_pressure_decay_sequence > 0:
            narrative_time_delta = self.narrative_tracker.get_narrative_time_since_sequence(
                self.last_pressure_decay_sequence
            )
        else:
            narrative_time_delta = 0.0
        
        # Calculate decay based on narrative minutes elapsed
        narrative_minutes = narrative_time_delta / 60.0
        decay = self.pressure_decay_per_minute * narrative_minutes
        
        # Apply pressure floor constraint
        effective_floor = max(self.base_pressure_floor, 0.0)
        self.pressure_level = max(effective_floor, self.pressure_level - decay)
        
        # Update last decay sequence
        self.last_pressure_decay_sequence = self.narrative_tracker.exchange_count
        
        if self.debug_logger and decay > 0:
            self._log_debug(f"Narrative decay: {decay:.3f} over {narrative_minutes:.1f} narrative minutes")
    
    def process_user_input(self, input_text: str) -> Dict[str, Any]:
        """
        Process user input and update story momentum using narrative time.
        Provides immediate feedback while preparing for LLM analysis cycles.
        """
        
        # Add exchange to narrative time tracker
        narrative_duration = self.narrative_tracker.add_exchange(input_text)
        
        # Apply narrative-time-based pressure decay
        self._apply_narrative_pressure_decay()
        
        # Calculate immediate pressure change using pattern matching
        pressure_change = self._calculate_pressure_change(input_text)
        old_pressure = self.pressure_level
        
        # Apply pressure floor ratcheting
        effective_floor = max(self.base_pressure_floor, 0.0)
        self.pressure_level = max(effective_floor, min(1.0, self.pressure_level + pressure_change))
        
        # Record pressure history with narrative time
        self.pressure_history.append((
            self.narrative_tracker.exchange_count,
            self.pressure_level,
            self.narrative_tracker.total_narrative_seconds
        ))
        
        if len(self.pressure_history) > 200:
            self.pressure_history = self.pressure_history[-100:]
        
        # Update story arc
        old_arc = self.story_arc
        self._update_story_arc()
        
        # Antagonist management (basic threshold check)
        antagonist_introduced = self._manage_antagonist_threshold()
        
        self._log_debug(f"Pressure: {old_pressure:.3f} → {self.pressure_level:.3f} (+{pressure_change:.3f}), "
                       f"Duration: {narrative_duration:.1f}s")
        
        return {
            "status": "processed",
            "pressure": self.pressure_level,
            "pressure_change": pressure_change,
            "arc": self.story_arc.value,
            "arc_changed": old_arc != self.story_arc,
            "antagonist_introduced": antagonist_introduced,
            "antagonist_active": self.current_antagonist is not None,
            "narrative_duration": narrative_duration,
            "total_narrative_time": self.narrative_tracker.total_narrative_seconds,
            "needs_llm_analysis": False  # Will be determined by message count
        }
    
    def _update_story_arc(self):
        """Update story arc based on pressure level"""
        if self.pressure_level < 0.3:
            self.story_arc = StoryArc.SETUP
        elif self.pressure_level < 0.7:
            self.story_arc = StoryArc.RISING
        elif self.pressure_level < 0.9:
            self.story_arc = StoryArc.CLIMAX
        else:
            self.story_arc = StoryArc.RESOLUTION
    
    def _manage_antagonist_threshold(self) -> bool:
        """Basic antagonist introduction based on pressure threshold"""
        if (self.pressure_level >= self.pressure_threshold_antagonist and 
            self.current_antagonist is None):
            # Create basic antagonist - will be enhanced by LLM analysis
            self.current_antagonist = self._create_basic_antagonist()
            self._log_debug(f"Basic antagonist introduced: {self.current_antagonist.name}")
            return True
        
        # Deactivate antagonist during resolution
        if (self.story_arc == StoryArc.RESOLUTION and 
            self.current_antagonist and self.current_antagonist.active):
            self.current_antagonist.active = False
            self._log_debug("Antagonist deactivated for resolution")
        
        return False
    
    def _create_basic_antagonist(self) -> Antagonist:
        """Create basic antagonist for immediate use (enhanced later by LLM)"""
        antagonist = Antagonist(
            name="Shadow Entity",
            motivation="opposes the player's progress",
            threat_level=min(0.9, self.pressure_level + 0.1),
            context="adaptive_threat"
        )
        antagonist.commitment_level = "testing"
        antagonist.resources_available = ["stealth", "cunning", "persistence"]
        antagonist.personality_traits = ["mysterious", "adaptive", "persistent"]
        antagonist.introduction_sequence = self.narrative_tracker.exchange_count
        return antagonist

    def should_analyze_momentum(self, total_message_count: int) -> bool:
        """Check if momentum analysis should be triggered (every 15 messages)"""
        if total_message_count < 15:
            return False  # Grace period for initial conversation
        
        return total_message_count - self.last_analysis_count >= 15
    
    def prepare_momentum_analysis_context(self, conversation_messages: List[Dict[str, Any]], max_tokens: int = 6000) -> Tuple[List[Dict[str, Any]], int]:
        """Prepare context for momentum analysis within allocated budget"""
        # Reserve 25% for analysis prompt overhead
        analysis_overhead = max_tokens // 4
        available_tokens = max_tokens - analysis_overhead
        
        # Start with recent messages and work backwards
        context_messages = []
        total_tokens = 0
        
        for message in reversed(conversation_messages):
            content = message.get("content", "")
            message_tokens = len(content) // 4  # Conservative token estimation
            
            if total_tokens + message_tokens <= available_tokens:
                context_messages.insert(0, message)
                total_tokens += message_tokens
            else:
                break
        
        self._log_debug(f"Momentum analysis context: {len(context_messages)} messages, {total_tokens} tokens")
        return context_messages, total_tokens

# Chunk 3/3 - sme.py - LLM Analysis and State Persistence with Narrative Time

    async def analyze_momentum(self, conversation_messages: List[Dict[str, Any]], total_message_count: int, is_first_analysis: bool = False) -> Dict[str, Any]:
        """
        Unified momentum analysis function that handles both first-time and regular analysis.
        """
        
        # 1. Prepare context within token budget
        context_messages, context_tokens = self.prepare_momentum_analysis_context(
            conversation_messages, max_tokens=6000
        )
        
        # 2. Handle antagonist generation/validation
        if is_first_analysis or not self.current_antagonist or not self.validate_antagonist_quality(self.current_antagonist):
            self._log_debug("Generating/enhancing antagonist for momentum analysis...")
            antagonist = await self.generate_antagonist(context_messages)
            if antagonist:
                self.current_antagonist = antagonist
        
        # 3. Resource loss analysis
        conversation_text = "\n".join([
            f"{m.get('role', 'unknown')}: {m.get('content', '')}"
            for m in context_messages[-10:]  # Last 10 messages
        ])
        
        events_occurred = await self.analyze_resource_loss(conversation_text, self.current_antagonist)
        
        # 4. Calculate pressure floor ratcheting
        new_pressure_floor = self.calculate_pressure_floor_ratchet(events_occurred.get("events", []))
        
        # 5. Main momentum analysis with narrative time context
        current_state = self.get_current_state()
        narrative_stats = self.narrative_tracker.get_stats()
        momentum_prompt = self._create_momentum_analysis_prompt(current_state, context_messages, events_occurred, new_pressure_floor, narrative_stats)
        
        self._log_debug(f"Running momentum analysis with {len(context_messages)} context messages")
        
        # 6. Execute analysis with error handling
        try:
            response = await self._call_llm([{"role": "system", "content": momentum_prompt}])
            if response:
                analysis_result = self._parse_momentum_response_robust(response)
                if analysis_result:
                    # Update state with analysis results
                    self._update_state_from_analysis(analysis_result, new_pressure_floor, total_message_count)
                    self._log_debug(f"Momentum analysis complete. Pressure: {self.pressure_level:.2f}")
                    return analysis_result
        
        except Exception as e:
            self._log_debug(f"Momentum analysis failed: {e}")
        
        # Return safe updated state on failure
        safe_state = current_state.copy()
        safe_state["last_analysis_count"] = total_message_count
        safe_state["base_pressure_floor"] = new_pressure_floor
        return safe_state
    
    def _create_momentum_analysis_prompt(self, current_state: Dict[str, Any], context_messages: List[Dict[str, Any]], events_occurred: Dict[str, Any], new_pressure_floor: float, narrative_stats: Dict[str, Any]) -> str:
        """Create comprehensive momentum analysis prompt with narrative time context"""
        
        conversation_text = "\n".join([
            f"{m.get('role', 'unknown')}: {m.get('content', '')[:300]}"  # Truncate for efficiency
            for m in context_messages
        ])
        
        antagonist_info = "None"
        if self.current_antagonist:
            antagonist_info = f"{self.current_antagonist.name} - {self.current_antagonist.motivation} (commitment: {self.current_antagonist.commitment_level})"
        
        return f"""You are analyzing story momentum in an ongoing RPG narrative. Based on the conversation 
and current momentum state, provide updated momentum metrics.

Current Momentum State:
- Narrative Pressure: {self.pressure_level:.2f}
- Story Arc: {self.story_arc.value}
- Antagonist: {antagonist_info}
- Escalation Count: {self.escalation_count}
- Pressure Floor: {self.base_pressure_floor:.2f} → {new_pressure_floor:.2f}

Narrative Time Context:
- Total Narrative Time: {narrative_stats.get('narrative_time_formatted', 'unknown')}
- Average Exchange Duration: {narrative_stats.get('average_duration_per_exchange', 0):.1f}s
- Total Exchanges: {narrative_stats.get('exchange_count', 0)}

Recent Events Detected: {events_occurred}

Recent Conversation:
{conversation_text}

Analyze and provide updated momentum state:

1. How has narrative pressure changed? (0.0-1.0 scale, considering floor of {new_pressure_floor:.2f})
2. What is the pressure source? (antagonist/environment/social/discovery)
3. How is momentum manifesting? (exploration/tension/conflict/resolution)
4. What is the player's behavioral pattern? (aggressive/cautious/avoidant/diplomatic)
5. How should the antagonist respond given their commitment level?
6. Should the antagonist's commitment level change? (testing/engaged/desperate/cornered)

Return JSON format:
{{
  "narrative_pressure": 0.0-1.0,
  "pressure_source": "antagonist|environment|social|discovery",
  "manifestation_type": "exploration|tension|conflict|resolution",
  "player_behavior": "aggressive|cautious|avoidant|diplomatic",
  "antagonist_response": "description of how antagonist should respond",
  "commitment_change": "testing|engaged|desperate|cornered|no_change",
  "escalation_events": ["event1", "event2"],
  "pressure_reasoning": "explanation of pressure changes"
}}"""
    
    def _parse_momentum_response_robust(self, response: str) -> Optional[Dict[str, Any]]:
        """Parse LLM momentum analysis response with 5-strategy defensive handling"""
        
        # Strategy 1: Direct JSON parsing
        try:
            data = json.loads(response.strip())
            if self._validate_momentum_data(data):
                return self._inject_momentum_defaults(data)
        except json.JSONDecodeError:
            pass
        
        # Strategy 2: Substring extraction
        try:
            start = response.find('{')
            end = response.rfind('}') + 1
            
            if start >= 0 and end > start:
                json_str = response[start:end]
                data = json.loads(json_str)
                if self._validate_momentum_data(data):
                    return self._inject_momentum_defaults(data)
        except (json.JSONDecodeError, ValueError):
            pass
        
        # Strategy 3: Field validation and pattern extraction
        try:
            extracted_data = {}
            
            # Extract pressure using regex
            pressure_match = re.search(r'"?narrative_pressure"?\s*:\s*([0-9.]+)', response)
            if pressure_match:
                extracted_data["narrative_pressure"] = float(pressure_match.group(1))
            
            # Extract source
            source_match = re.search(r'"?pressure_source"?\s*:\s*"([^"]+)"', response)
            if source_match:
                extracted_data["pressure_source"] = source_match.group(1)
            
            # Extract manifestation
            manifest_match = re.search(r'"?manifestation_type"?\s*:\s*"([^"]+)"', response)
            if manifest_match:
                extracted_data["manifestation_type"] = manifest_match.group(1)
            
            if extracted_data:
                return self._inject_momentum_defaults(extracted_data)
        except:
            pass
        
        # Strategy 4: Default injection based on keywords
        try:
            response_lower = response.lower()
            extracted_data = {}
            
            # Infer pressure from keywords
            if "high" in response_lower or "intense" in response_lower:
                extracted_data["narrative_pressure"] = 0.7
            elif "moderate" in response_lower or "medium" in response_lower:
                extracted_data["narrative_pressure"] = 0.5
            elif "low" in response_lower or "calm" in response_lower:
                extracted_data["narrative_pressure"] = 0.3
            
            # Infer source from keywords
            if "antagonist" in response_lower:
                extracted_data["pressure_source"] = "antagonist"
            elif "environment" in response_lower:
                extracted_data["pressure_source"] = "environment"
            elif "social" in response_lower:
                extracted_data["pressure_source"] = "social"
            elif "discovery" in response_lower:
                extracted_data["pressure_source"] = "discovery"
            
            if extracted_data:
                return self._inject_momentum_defaults(extracted_data)
        except:
            pass
        
        # Strategy 5: Complete fallback
        return self._create_fallback_momentum_state()
    
    def _validate_momentum_data(self, data: Dict[str, Any]) -> bool:
        """Validate that momentum analysis data has core required fields"""
        if not isinstance(data, dict):
            return False
        
        # Must have at least narrative_pressure
        if "narrative_pressure" not in data:
            return False
        
        pressure = data["narrative_pressure"]
        if not isinstance(pressure, (int, float)) or pressure < 0 or pressure > 1:
            return False
        
        return True
    
    def _inject_momentum_defaults(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Inject missing fields with sensible defaults"""
        defaults = {
            "narrative_pressure": self.pressure_level,
            "pressure_source": self._get_pressure_source(),
            "manifestation_type": self._get_manifestation_type(),
            "player_behavior": "cautious",
            "antagonist_response": "maintaining current strategy",
            "commitment_change": "no_change",
            "escalation_events": [],
            "pressure_reasoning": "analysis completed"
        }
        
        for key, default_value in defaults.items():
            if key not in data:
                data[key] = default_value
        
        # Validate pressure value
        pressure = data.get("narrative_pressure", self.pressure_level)
        if not isinstance(pressure, (int, float)) or pressure < 0 or pressure > 1:
            data["narrative_pressure"] = self.pressure_level
        
        return data
    
    def _create_fallback_momentum_state(self) -> Dict[str, Any]:
        """Create complete fallback momentum state"""
        return {
            "narrative_pressure": self.pressure_level,
            "pressure_source": self._get_pressure_source(),
            "manifestation_type": self._get_manifestation_type(),
            "player_behavior": "cautious",
            "antagonist_response": "maintaining current strategy",
            "commitment_change": "no_change",
            "escalation_events": [],
            "pressure_reasoning": "fallback analysis - LLM response parsing failed"
        }
    
    def _update_state_from_analysis(self, analysis: Dict[str, Any], new_pressure_floor: float, total_message_count: int):
        """Update internal state from LLM analysis results"""
        # Update pressure with floor constraint
        new_pressure = analysis.get("narrative_pressure", self.pressure_level)
        self.pressure_level = max(new_pressure, new_pressure_floor)
        
        # Update pressure floor
        self.base_pressure_floor = new_pressure_floor
        
        # Update analysis tracking
        self.last_analysis_count = total_message_count
        
        # Update antagonist commitment if specified
        if self.current_antagonist and "commitment_change" in analysis:
            commitment = analysis["commitment_change"]
            if commitment != "no_change":
                self.current_antagonist.commitment_level = commitment
                self._log_debug(f"Antagonist commitment updated to: {commitment}")
        
        # Track escalation events
        escalation_events = analysis.get("escalation_events", [])
        if escalation_events:
            self.escalation_count += len(escalation_events)
    
    # [Additional methods like generate_antagonist, analyze_resource_loss, etc. remain the same]
    # [Continuing with remaining core methods...]
    
    def get_current_state(self) -> Dict[str, Any]:
        """Get current momentum state for analysis"""
        return {
            "narrative_pressure": self.pressure_level,
            "pressure_source": self._get_pressure_source(),
            "manifestation_type": self._get_manifestation_type(),
            "escalation_count": self.escalation_count,
            "base_pressure_floor": self.base_pressure_floor,
            "last_analysis_count": self.last_analysis_count,
            "antagonist": self.current_antagonist.to_dict() if self.current_antagonist else None,
            "story_arc": self.story_arc.value,
            "narrative_time_stats": self.narrative_tracker.get_stats()
        }
    
    def _get_pressure_source(self) -> str:
        """Determine current pressure source"""
        if self.current_antagonist and self.current_antagonist.active:
            return "antagonist"
        elif self.pressure_level > 0.5:
            return "environment"
        else:
            return "exploration"
    
    def _get_manifestation_type(self) -> str:
        """Determine how momentum is currently manifesting"""
        if self.story_arc == StoryArc.SETUP:
            return "exploration"
        elif self.story_arc == StoryArc.RISING:
            return "tension"
        elif self.story_arc == StoryArc.CLIMAX:
            return "conflict"
        else:
            return "resolution"
    
    def get_story_context(self) -> Dict[str, Any]:
        """Generate story context for MCP module integration"""
        narrative_stats = self.narrative_tracker.get_stats()
        
        context = {
            "pressure_level": round(self.pressure_level, 3),
            "story_arc": self.story_arc.value,
            "narrative_state": self._get_narrative_state_description(),
            "should_introduce_tension": self.pressure_level < 0.4,
            "climax_approaching": self.pressure_level > 0.7,
            "antagonist_present": self.current_antagonist is not None and self.current_antagonist.active,
            "pressure_floor": self.base_pressure_floor,
            "narrative_time": narrative_stats.get('narrative_time_formatted', '0s'),
            "total_exchanges": narrative_stats.get('exchange_count', 0)
        }
        
        if self.current_antagonist:
            context["antagonist"] = {
                "name": self.current_antagonist.name,
                "motivation": self.current_antagonist.motivation,
                "threat_level": self.current_antagonist.threat_level,
                "active": self.current_antagonist.active,
                "commitment_level": self.current_antagonist.commitment_level,
                "resources_lost": len(self.current_antagonist.resources_lost)
            }
        
        # Recent pressure trend using narrative time
        if len(self.pressure_history) >= 3:
            recent_pressures = [p[1] for p in self.pressure_history[-3:]]
            if recent_pressures[-1] > recent_pressures[0]:
                context["pressure_trend"] = "rising"
            elif recent_pressures[-1] < recent_pressures[0]:
                context["pressure_trend"] = "falling"
            else:
                context["pressure_trend"] = "stable"
        else:
            context["pressure_trend"] = "initializing"
        
        return context
    
    def _get_narrative_state_description(self) -> str:
        """Generate narrative state description for context"""
        if self.story_arc == StoryArc.SETUP:
            if self.pressure_level < 0.2:
                return "calm_exploration"
            else:
                return "building_tension"
        elif self.story_arc == StoryArc.RISING:
            return "escalating_conflict"
        elif self.story_arc == StoryArc.CLIMAX:
            return "peak_intensity"
        else:  # RESOLUTION
            return "concluding_action"
    
    def reset_story_state(self):
        """Reset story state for new session"""
        self.pressure_level = 0.0
        self.story_arc = StoryArc.SETUP
        self.current_antagonist = None
        self.pressure_history.clear()
        self.last_analysis_count = 0
        self.escalation_count = 0
        self.base_pressure_floor = 0.0
        self.last_pressure_decay_sequence = 0
        self.narrative_tracker = NarrativeTimeTracker()
        self._log_debug("Story state reset with narrative time tracking")
    
    def get_pressure_stats(self) -> Dict[str, Any]:
        """Get pressure statistics for analysis"""
        if not self.pressure_history:
            return {"status": "no_data"}
        
        pressures = [p[1] for p in self.pressure_history]
        narrative_times = [p[2] for p in self.pressure_history]
        
        narrative_stats = self.narrative_tracker.get_stats()
        
        stats = {
            "current_pressure": self.pressure_level,
            "average_pressure": sum(pressures) / len(pressures),
            "max_pressure": max(pressures),
            "min_pressure": min(pressures),
            "pressure_variance": self._calculate_variance(pressures),
            "narrative_duration": narrative_stats.get('total_narrative_seconds', 0),
            "total_updates": len(self.pressure_history),
            "current_arc": self.story_arc.value,
            "pressure_floor": self.base_pressure_floor,
            "escalation_count": self.escalation_count,
            "last_analysis_count": self.last_analysis_count,
            "narrative_time_formatted": narrative_stats.get('narrative_time_formatted', '0s'),
            "average_exchange_duration": narrative_stats.get('average_duration_per_exchange', 0)
        }
        
        return stats
    
    def _calculate_variance(self, values: List[float]) -> float:
        """Calculate variance of pressure values"""
        if len(values) < 2:
            return 0.0
        
        mean = sum(values) / len(values)
        squared_diffs = [(x - mean) ** 2 for x in values]
        return sum(squared_diffs) / len(squared_diffs)
    
    # State persistence methods for EMM integration
    def save_state_to_dict(self) -> Dict[str, Any]:
        """Save SME state to dictionary for EMM storage"""
        narrative_stats = self.narrative_tracker.get_stats()
        
        return {
            "narrative_pressure": self.pressure_level,
            "pressure_source": self._get_pressure_source(),
            "manifestation_type": self._get_manifestation_type(),
            "escalation_count": self.escalation_count,
            "base_pressure_floor": self.base_pressure_floor,
            "last_analysis_count": self.last_analysis_count,
            "antagonist": self.current_antagonist.to_dict() if self.current_antagonist else None,
            "story_arc": self.story_arc.value,
            "pressure_history": self.pressure_history[-10:],  # Save last 10 pressure points
            "narrative_time_total": self.narrative_tracker.total_narrative_seconds,
            "narrative_exchange_count": self.narrative_tracker.exchange_count,
            "last_pressure_decay_sequence": self.last_pressure_decay_sequence,
            "timestamp": datetime.now().isoformat()  # Real time for file metadata
        }
    
    def load_state_from_dict(self, state_data: Dict[str, Any]) -> bool:
        """Load SME state from dictionary (from EMM)"""
        try:
            self.pressure_level = max(0.0, min(1.0, state_data.get("narrative_pressure", 0.0)))
            self.escalation_count = max(0, state_data.get("escalation_count", 0))
            self.base_pressure_floor = max(0.0, min(0.3, state_data.get("base_pressure_floor", 0.0)))
            self.last_analysis_count = max(0, state_data.get("last_analysis_count", 0))
            self.last_pressure_decay_sequence = max(0, state_data.get("last_pressure_decay_sequence", 0))
            
            # Restore narrative time tracking
            self.narrative_tracker.total_narrative_seconds = state_data.get("narrative_time_total", 0.0)
            self.narrative_tracker.exchange_count = state_data.get("narrative_exchange_count", 0)
            
            # Load story arc
            arc_value = state_data.get("story_arc", "setup")
            try:
                self.story_arc = StoryArc(arc_value)
            except ValueError:
                self.story_arc = StoryArc.SETUP
            
            # Load antagonist
            antagonist_data = state_data.get("antagonist")
            if antagonist_data:
                self.current_antagonist = Antagonist.from_dict(antagonist_data)
            else:
                self.current_antagonist = None
            
            # Load pressure history
            pressure_history = state_data.get("pressure_history", [])
            if isinstance(pressure_history, list):
                self.pressure_history = pressure_history
            
            self._log_debug("SME state loaded with narrative time tracking")
            return True
            
        except Exception as e:
            self._log_debug(f"Failed to load SME state: {e}")
            return False

# [Additional utility methods and module test remain similar to original]

if __name__ == "__main__":
    # Basic functionality test with semantic time detection
    sme = StoryMomentumEngine()
    
    test_inputs = [
        "I look around the room carefully",
        "I hear strange noises coming from the shadows", 
        "I draw my weapon and prepare for battle",
        "The enemy attacks with fierce intensity!",
        "After some time, we continue our journey",
        "I carefully examine the ancient runes for several minutes"
    ]
    
    print("SME Test Run with Semantic Time Detection:")
    for input_text in test_inputs:
        result = sme.process_user_input(input_text)
        duration = result.get('narrative_duration', 0)
        narrative_time = result.get('total_narrative_time', 0)
        print(f"Input: {input_text}")
        print(f"Duration: {duration:.1f}s | Total: {narrative_time:.1f}s | Pressure: {result['pressure']:.3f}")
        print("---")
    
    print(f"Final Stats: {sme.get_pressure_stats()}")
